## Hi there 👋

🚀 Passionate **GCP Cloud Data Engineer** with 2.6+ years of experience delivering scalable, high-performance data solutions for enterprise applications. Skilled in designing **real-time streaming** and **batch processing pipelines** that transform raw data into actionable insights. Focused on building robust data architectures, optimizing performance, and enabling organizations to unlock the full potential of their data.  

---

## 📈 What I Do Best  
- ✅ **Batch Pipelines:** Large-scale ETL workflows with Airflow & Dataproc for cost-efficient processing  
- ✅ **Real-Time Pipelines:** Ingest & process millions of events/sec using Kafka, Pub/Sub & Spark Streaming  
- ✅ **Data Warehousing & Analytics:** Optimized schemas & queries in BigQuery, Hive, and Snowflake  
- ✅ **Performance Tuning:** Reduced processing costs & latency via partitioning, caching & autoscaling  
- ✅ **Multi-Cloud & Hybrid:** Seamless integration of GCP with external sources & on-prem systems  

---

## 🛠 Tech Stack & Tools  

**⚡ Languages & Processing:** Python | PySpark | Apache Spark | Apache Beam | Apache Flink  
**🗄 Databases:** SQL | SQL Server | MySQL | PostgreSQL | MongoDB | Cassandra  
**☁ Cloud & Big Data:** GCP (BigQuery | Dataproc | Dataflow | Pub/Sub | Composer) | Databricks | Hadoop | Hive | Snowflake  
**🔄 Orchestration:** Apache Airflow | Cloud Composer  
**📡 Messaging & Streaming:** Kafka | Pub/Sub  
**📊 Core Areas:** ETL/ELT Development | Data Lake & Warehouse Design | Data Quality Validation | Performance Optimization  

---

## 💡 My Approach  
Data engineering is more than just moving data — it’s about building ecosystems that are **fast, resilient, and insightful**, enabling teams to make better, smarter, and faster decisions.  

---

## 📩 Open To  
**Data Engineer | Big Data Engineer | Cloud Data Engineer** opportunities  

---
🤝 Let’s connect and make data work smarter!  

